import os
import sys
import subprocess
from pathlib import Path
import gradio as gr
from pydub import AudioSegment
import numpy as np
import torch
import time
from colorama import init, Fore, Style
from audiocraft.models import MusicGen
from ffmpeg_utils import print_audio_comparison, process_existing_audio

# --- –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ ---
init(autoreset=True)
OUTPUT_DIR = Path("Leon_vibe")
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
print(Fore.YELLOW + "–ó–∞–ø—É—Å–∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è... –í—Å–µ —Ç—Ä–µ–∫–∏ –±—É–¥—É—Ç –≤ –ø–∞–ø–∫–µ 'Leon_vibe'")

# --- –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ ---
print(Fore.YELLOW + "–ó–∞–≥—Ä—É–∂–∞—é –º–æ–¥–µ–ª—å MusicGen (facebook/musicgen-small)...")
model = MusicGen.get_pretrained("facebook/musicgen-small")
print(Fore.GREEN + "–ú–æ–¥–µ–ª—å MusicGen –∑–∞–≥—Ä—É–∂–µ–Ω–∞. –ì–æ—Ç–æ–≤–æ.")

# --- –§—É–Ω–∫—Ü–∏–∏-–ø–æ–º–æ—â–Ω–∏–∫–∏ ---
def create_safe_filename(name: str) -> str:
    safe = "".join(c for c in name if c.isalnum() or c in "_- ").rstrip()
    return safe or "track"

def audio_write(path: str, audio_tensor: torch.Tensor, sample_rate: int):
    audio_np = audio_tensor.cpu().numpy()
    if audio_np.ndim > 1: audio_np = audio_np[0]
    audio_int16 = (audio_np * 32767).astype(np.int16)
    AudioSegment(audio_int16.tobytes(), frame_rate=sample_rate, sample_width=2, channels=1).export(path, format="wav")

def list_audio_files():
    files = list(OUTPUT_DIR.glob("*.wav")) + list(OUTPUT_DIR.glob("*.mp3"))
    files.sort(key=os.path.getmtime, reverse=True)
    return [str(p.resolve()) for p in files]

def delete_file(path_str: str):
    if path_str and Path(path_str).exists():
        Path(path_str).unlink()
    updated_choices = gr.update(choices=list_audio_files())
    return updated_choices, updated_choices

# --- –û—Å–Ω–æ–≤–Ω–æ–π workflow –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å –ö–†–ê–°–ò–í–û–ô –ê–ù–ò–ú–ê–¶–ò–ï–ô ---
def generate_music_workflow(prompt: str, duration: int, track_name: str, process_audio: bool, progress=gr.Progress(track_tqdm=True)):
    try:
        # --- –®–∞–≥ 1: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å –ø–ª–∞–≤–Ω–æ–π –∞–Ω–∏–º–∞—Ü–∏–µ–π ---
        model.set_generation_params(duration=int(duration))
        
        # –í–∏–∑—É–∞–ª—å–Ω–∞—è —Å–∏–º—É–ª—è—Ü–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –¥–ª—è –ª—É—á—à–µ–≥–æ UX
        num_steps = 30 # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ "—à–∞–≥–æ–≤" –∞–Ω–∏–º–∞—Ü–∏–∏
        for _ in progress.tqdm(range(num_steps), desc="–®–∞–≥ 1/2: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –º—É–∑—ã–∫–∏..."):
            # –í—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è –∑–∞–≤–∏—Å–∏—Ç –æ—Ç –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Ç—Ä–µ–∫–∞, —á—Ç–æ–±—ã –∞–Ω–∏–º–∞—Ü–∏—è –±—ã–ª–∞ —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω–æ–π
            time.sleep(duration / num_steps)
        
        # –ù–∞—Å—Ç–æ—è—â–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è
        wavs = model.generate([prompt])
        
        # --- –®–∞–≥ 2: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏ –û–±—Ä–∞–±–æ—Ç–∫–∞ ---
        progress(0.9, desc="–®–∞–≥ 2/2: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞...")
        safe_name = create_safe_filename(track_name)
        wav_path = OUTPUT_DIR / f"{safe_name}.wav"
        audio_write(str(wav_path), wavs[0].cpu(), model.sample_rate)
        
        if process_audio:
            processed_path, _ = process_existing_audio(str(wav_path))
            return processed_path or str(wav_path)
        else:
            return str(wav_path)
            
    except Exception as e:
        raise gr.Error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")

# --- Gradio UI ---
with gr.Blocks(theme=gr.themes.Soft(primary_hue=gr.themes.colors.purple, secondary_hue=gr.themes.colors.blue)) as demo:
    gr.Markdown("# üéµ Leon's Vibe Creator (MusicGen) üéµ")
    
    with gr.Tab("–°–æ–∑–¥–∞–Ω–∏–µ –∏ –£–ª—É—á—à–µ–Ω–∏–µ"):
        gr.Markdown("### –®–∞–≥ 1: –°–æ–∑–¥–∞–π—Ç–µ –Ω–æ–≤—ã–π —Ç—Ä–µ–∫")
        with gr.Row():
            prompt_input = gr.Textbox(label="–í–≤–µ–¥–∏—Ç–µ –ø—Ä–æ–º–ø—Ç (–ª—É—á—à–µ –Ω–∞ –∞–Ω–≥–ª.)", lines=2, value="lofi relaxing piano")
            with gr.Column():
                track_name_input = gr.Textbox(label="–ù–∞–∑–≤–∞–Ω–∏–µ —Ç—Ä–µ–∫–∞ (–∏–º—è —Ñ–∞–π–ª–∞)", value="Leon_music")
                duration_input = gr.Slider(minimum=5, maximum=60, value=20, step=1, label="–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å (—Å–µ–∫—É–Ω–¥)")
        process_checkbox = gr.Checkbox(label="–°—Ä–∞–∑—É —É–ª—É—á—à–∏—Ç—å –∞—É–¥–∏–æ (ffmpeg)", value=True)
        generate_button = gr.Button("1. –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å", variant="primary")
        generated_audio_output = gr.Audio(label="–†–µ–∑—É–ª—å—Ç–∞—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏", type="filepath")

        gr.Markdown("--- \n ### –®–∞–≥ 2: –£–ª—É—á—à–∏—Ç–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π —Ç—Ä–µ–∫")
        files_list_process = gr.Dropdown(label="–í—ã–±–µ—Ä–∏—Ç–µ —Ñ–∞–π–ª –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è", choices=list_audio_files(), interactive=True)
        process_button = gr.Button("2. –£–ª—É—á—à–∏—Ç—å –≤—ã–±—Ä–∞–Ω–Ω—ã–π —Ñ–∞–π–ª")
        processed_audio_output = gr.Audio(label="–†–µ–∑—É–ª—å—Ç–∞—Ç —É–ª—É—á—à–µ–Ω–∏—è", type="filepath")
        status_text = gr.Textbox(label="–°—Ç–∞—Ç—É—Å", interactive=False)

    with gr.Tab("–§–∞–π–ª–æ–≤—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä"):
        files_list_manage = gr.Dropdown(label="–°–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤ –≤ –ø–∞–ø–∫–µ", choices=list_audio_files(), interactive=True)
        with gr.Row():
            play_button = gr.Button("–ü—Ä–æ—Å–ª—É—à–∞—Ç—å –≤—ã–±—Ä–∞–Ω–Ω—ã–π —Ñ–∞–π–ª")
            delete_button = gr.Button("–£–¥–∞–ª–∏—Ç—å –≤—ã–±—Ä–∞–Ω–Ω—ã–π —Ñ–∞–π–ª")
        audio_player = gr.Audio(label="–ü–ª–µ–µ—Ä", type="filepath")

    # --- –õ–æ–≥–∏–∫–∞ –∫–Ω–æ–ø–æ–∫ ---
    def on_generate_and_update(prompt, duration, track_name, process_audio, progress=gr.Progress(track_tqdm=True)):
        path = generate_music_workflow(prompt, duration, track_name, process_audio, progress)
        updated_list = gr.update(choices=list_audio_files(), value=path)
        return path, updated_list, updated_list

    def on_process_and_update(filepath, progress=gr.Progress(track_tqdm=True)):
        path, status = process_existing_audio(filepath, progress)
        updated_list = gr.update(choices=list_audio_files(), value=path)
        return path, status, updated_list, updated_list
    
    generate_button.click(
        on_generate_and_update,
        inputs=[prompt_input, duration_input, track_name_input, process_checkbox],
        outputs=[generated_audio_output, files_list_process, files_list_manage]
    )
    process_button.click(
        on_process_and_update,
        inputs=[files_list_process],
        outputs=[processed_audio_output, status_text, files_list_process, files_list_manage]
    )
    play_button.click(lambda p: p, inputs=[files_list_manage], outputs=[audio_player])
    delete_button.click(delete_file, inputs=[files_list_manage], outputs=[files_list_process, files_list_manage])

if __name__ == "__main__":
    demo.launch()